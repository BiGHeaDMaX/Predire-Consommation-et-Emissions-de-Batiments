{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modèle de référence (dummy)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importation des bibliothèques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pour les traîtements sur les variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Modèle de ML utilisé\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Pour gridsearch\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importation du dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importation terminée\n"
     ]
    }
   ],
   "source": [
    "dataset_a_utiliser = \"data_clean.xlsx\"\n",
    "\n",
    "data = pd.read_excel(dataset_a_utiliser)\n",
    "print('Importation terminée')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Split & Scale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split & Scale : OK\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Choix des features #\n",
    "######################\n",
    "\n",
    "features_list = [\n",
    "                 'BuildingType',\n",
    "                 'PrimaryPropertyType',\n",
    "                 'Neighborhood',\n",
    "                 'YearBuilt',\n",
    "                 'NumberofBuildings',\n",
    "                 'NumberofFloors',\n",
    "                 'PropertyGFAParking',\n",
    "                 'PropertyGFABuilding(s)'\n",
    "                ]\n",
    "\n",
    "y_column = 'SiteEnergyUseWN_kBtu'\n",
    "#y_column = 'TotalGHGEmissions'\n",
    "\n",
    "###############################\n",
    "# Split du dataset par X et y #\n",
    "###############################\n",
    "\n",
    "X = data.loc[:,features_list] # On ajoute nos features dans le X\n",
    "y = data.loc[:,y_column] # On ajoute ce qu'on veut prédire dans le y\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# Scaling des données quantitatives et qualitatives (si existantes) #\n",
    "# Je fais le scale ici car il y a des 'YearBuilt' uniques (ex 1939) #\n",
    "# et du coup je ne pourrai pas faire un transform sur X_test        #\n",
    "#####################################################################\n",
    "\n",
    "categorical_features = [\n",
    "                        'BuildingType',\n",
    "                        'PrimaryPropertyType',\n",
    "                        'Neighborhood',\n",
    "                        'YearBuilt'\n",
    "                       ]\n",
    "\n",
    "numeric_features = [\n",
    "                    'NumberofBuildings',\n",
    "                    'NumberofFloors',\n",
    "                    'PropertyGFAParking',\n",
    "                    'PropertyGFABuilding(s)'\n",
    "                   ]\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', categorical_transformer, categorical_features),    \n",
    "                ('num', numeric_transformer, numeric_features)\n",
    "                ]\n",
    "            )\n",
    "X = feature_encoder.fit_transform(X)\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Split du dataset en train et test #\n",
    "#####################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0\n",
    "                                                    )\n",
    "                                                    #stratify=y) # : Stratification du sample. \n",
    "                                                    # Il y aura alors la même proportion\n",
    "                                                    # de catégories dans les sets de test et train.\n",
    "                                                    # Utile surtout s'il y a peu de lignes dans le dataset.\n",
    "                                                    # Peut causer une erreur si certaines catégories n'ont pas assez de représentants\n",
    "\n",
    "\n",
    "print(\"Split & Scale : OK\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entraînement du modèle *DummyRegressor()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement : OK\n"
     ]
    }
   ],
   "source": [
    "modele = DummyRegressor() # Stratégie par défaut : mean\n",
    "modele.fit(X_train, y_train) # Étape d'entraînement\n",
    "print(\"Entraînement : OK\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Score du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score R² du modèle est de 0.000 (train) et -0.013 (test).\n"
     ]
    }
   ],
   "source": [
    "print(f\"Le score R² du modèle est de {modele.score(X_train, y_train):.3f} (train) et {modele.score(X_test, y_test):.3f} (test).\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GridSearch - DummyRegressor()**\n",
    "\n",
    "Test des meilleurs hyperparamètres. Dans le cadre d'une régression linéraire simple, pas grand chose à tester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement : {'constant': 58114, 'quantile': 0.75, 'strategy': 'quantile'}\n",
      "\n",
      "\n",
      "Score sur le jeu de test (avec paramètres optimaux): -0.011\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Paramétrage de GridSearchCV et entraînement #\n",
    "###############################################\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'strategy':['mean', 'median', 'quantile', 'constant'], 'constant':range(int(data[y_column].min()), int(data[y_column].max()), int(data[y_column].max()/3)), 'quantile':[0.0, 0.25, 0.5, 0.75, 1.0]}\n",
    "# Pour constant j'ai fait un range de min y à max y, avec un pas de max/3\n",
    "\n",
    "# Déterminer le score qu'on veut optimiser\n",
    "score = 'r2'\n",
    "\n",
    "# Je le sors ici car je vais réutiliser cette valeur plus tard\n",
    "cv = 5\n",
    "\n",
    "grid = model_selection.GridSearchCV(\n",
    "    DummyRegressor(), # On indique le modèle à tester\n",
    "    param_grid,     # hyperparamètres à tester\n",
    "    cv=cv,           # nombre de folds de validation croisée\n",
    "    scoring=score   # score à optimiser\n",
    ")\n",
    "\n",
    "# Optimiser ce modèle sur le jeu d'entraînement\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "###########################\n",
    "# Affichage des résultats #\n",
    "###########################\n",
    "\n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(f\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement : {grid.best_params_}\\n\")\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "# print('Résultats pour chaque fold :')\n",
    "# for i in range(cv):\n",
    "#    print(f\"Fold n°{i+1} :\", eval(f\"grid.cv_results_['split{i}_test_score']\"), f\"(Pour les paramètres : {grid.cv_results_['params']})\")\n",
    "\n",
    "#print(\"\\nRésultats de la validation croisée :\")\n",
    "#for mean, std, params in zip(\n",
    "#        grid.cv_results_['mean_test_score'], # score moyen\n",
    "#        grid.cv_results_['std_test_score'],  # écart-type du score\n",
    "#        grid.cv_results_['params']           # valeur de l'hyperparamètre\n",
    "#    ):\n",
    "\n",
    "#    print(f\"{score} (moyen) : {mean:.04f} (+/-{std*2:.04f}) pour {params}\")\n",
    "\n",
    "###################################################################\n",
    "# Prédiction sur le jeu de test avec les hyperparamètres optimaux #\n",
    "###################################################################\n",
    "\n",
    "# GridSearchCV a automatiquement ré-entraîné le meilleur modèle sur l’intégralité du jeu d’entraînement.\n",
    "y_pred = grid.predict(X_test)\n",
    "print(f\"\\nScore sur le jeu de test (avec paramètres optimaux): {metrics.r2_score(y_test, y_pred):.3f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entraînement du modèle *DummyClassifier***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Au préalable je dois refaire le split and scale, puisque y change.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split & Scale : OK\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Choix des features #\n",
    "######################\n",
    "\n",
    "features_list = [\n",
    "                 'BuildingType',\n",
    "                 'PrimaryPropertyType',\n",
    "                 'Neighborhood',\n",
    "                 'YearBuilt',\n",
    "                 'NumberofBuildings',\n",
    "                 'NumberofFloors',\n",
    "                 'PropertyGFAParking',\n",
    "                 'PropertyGFABuilding(s)'\n",
    "                ]\n",
    "\n",
    "y_column = 'SiteEnergyUseWN_kBtu_cat'\n",
    "#y_column = 'TotalGHGEmissions_cat'\n",
    "\n",
    "###############################\n",
    "# Split du dataset par X et y #\n",
    "###############################\n",
    "\n",
    "X = data.loc[:,features_list] # On ajoute nos features dans le X\n",
    "y = data.loc[:,y_column] # On ajoute ce qu'on veut prédire dans le y\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# Scaling des données quantitatives et qualitatives (si existantes) #\n",
    "# Je fais le scale ici car il y a des 'YearBuilt' uniques (ex 1939) #\n",
    "# et du coup je ne pourrai pas faire un transform sur X_test        #\n",
    "#####################################################################\n",
    "\n",
    "categorical_features = [\n",
    "                        'BuildingType',\n",
    "                        'PrimaryPropertyType',\n",
    "                        'Neighborhood',\n",
    "                        'YearBuilt'\n",
    "                       ]\n",
    "\n",
    "numeric_features = [\n",
    "                    'NumberofBuildings',\n",
    "                    'NumberofFloors',\n",
    "                    'PropertyGFAParking',\n",
    "                    'PropertyGFABuilding(s)'\n",
    "                   ]\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "feature_encoder = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', categorical_transformer, categorical_features),    \n",
    "                ('num', numeric_transformer, numeric_features)\n",
    "                ]\n",
    "            )\n",
    "X = feature_encoder.fit_transform(X)\n",
    "\n",
    "\n",
    "#####################################\n",
    "# Split du dataset en train et test #\n",
    "#####################################\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0\n",
    "                                                    )\n",
    "                                                    #stratify=y) # : Stratification du sample. \n",
    "                                                    # Il y aura alors la même proportion\n",
    "                                                    # de catégories dans les sets de test et train.\n",
    "                                                    # Utile surtout s'il y a peu de lignes dans le dataset.\n",
    "                                                    # Peut causer une erreur si certaines catégories n'ont pas assez de représentants\n",
    "\n",
    "\n",
    "print(\"Split & Scale : OK\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entraînement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement : OK\n"
     ]
    }
   ],
   "source": [
    "modele = DummyClassifier() # Stratégie par défaut : prior\n",
    "modele.fit(X_train, y_train) # Étape d'entraînement\n",
    "print(\"Entraînement : OK\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Score du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score du modèle est de 0.207 (train) et 0.170 (test).\n"
     ]
    }
   ],
   "source": [
    "print(f\"Le score du modèle est de {modele.score(X_train, y_train):.3f} (train) et {modele.score(X_test, y_test):.3f} (test).\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GridSearch - DummyClassifier()**\n",
    "\n",
    "Test des meilleurs hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement : {'strategy': 'most_frequent'}\n",
      "\n",
      "Résultats pour chaque fold :\n",
      "Fold n°1 : [0.20491803 0.20491803 0.15163934 0.22131148] (Pour les paramètres : [{'strategy': 'most_frequent'}, {'strategy': 'prior'}, {'strategy': 'stratified'}, {'strategy': 'uniform'}])\n",
      "Fold n°2 : [0.20491803 0.20491803 0.17622951 0.19672131] (Pour les paramètres : [{'strategy': 'most_frequent'}, {'strategy': 'prior'}, {'strategy': 'stratified'}, {'strategy': 'uniform'}])\n",
      "Fold n°3 : [0.20901639 0.20901639 0.18852459 0.20081967] (Pour les paramètres : [{'strategy': 'most_frequent'}, {'strategy': 'prior'}, {'strategy': 'stratified'}, {'strategy': 'uniform'}])\n",
      "Fold n°4 : [0.20901639 0.20901639 0.19262295 0.16393443] (Pour les paramètres : [{'strategy': 'most_frequent'}, {'strategy': 'prior'}, {'strategy': 'stratified'}, {'strategy': 'uniform'}])\n",
      "Fold n°5 : [0.20576132 0.20576132 0.18106996 0.22222222] (Pour les paramètres : [{'strategy': 'most_frequent'}, {'strategy': 'prior'}, {'strategy': 'stratified'}, {'strategy': 'uniform'}])\n",
      "\n",
      "Résultats de la validation croisée :\n",
      "accuracy (moyen) : 0.2067 (+/-0.0038) pour {'strategy': 'most_frequent'}\n",
      "accuracy (moyen) : 0.2067 (+/-0.0038) pour {'strategy': 'prior'}\n",
      "accuracy (moyen) : 0.1780 (+/-0.0287) pour {'strategy': 'stratified'}\n",
      "accuracy (moyen) : 0.2010 (+/-0.0425) pour {'strategy': 'uniform'}\n",
      "\n",
      "Score sur le jeu de test (avec paramètres optimaux): 0.170\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "# Paramétrage de GridSearchCV et entraînement #\n",
    "###############################################\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'strategy':['most_frequent', 'prior', 'stratified', 'uniform']}\n",
    "# Pour constant j'ai fait un range de min y à max y, avec un pas de max/3\n",
    "\n",
    "# Déterminer le score qu'on veut optimiser\n",
    "score = 'accuracy'\n",
    "\n",
    "# Je le sors ici car je vais réutiliser cette valeur plus tard\n",
    "cv = 5\n",
    "\n",
    "grid = model_selection.GridSearchCV(\n",
    "    DummyClassifier(), # On indique le modèle à tester\n",
    "    param_grid,     # hyperparamètres à tester\n",
    "    cv=cv,           # nombre de folds de validation croisée\n",
    "    scoring=score   # score à optimiser\n",
    ")\n",
    "\n",
    "# Optimiser ce modèle sur le jeu d'entraînement\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "###########################\n",
    "# Affichage des résultats #\n",
    "###########################\n",
    "\n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(f\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement : {grid.best_params_}\\n\")\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print('Résultats pour chaque fold :')\n",
    "for i in range(cv):\n",
    "    print(f\"Fold n°{i+1} :\", eval(f\"grid.cv_results_['split{i}_test_score']\"), f\"(Pour les paramètres : {grid.cv_results_['params']})\")\n",
    "\n",
    "print(\"\\nRésultats de la validation croisée :\")\n",
    "for mean, std, params in zip(\n",
    "        grid.cv_results_['mean_test_score'], # score moyen\n",
    "        grid.cv_results_['std_test_score'],  # écart-type du score\n",
    "        grid.cv_results_['params']           # valeur de l'hyperparamètre\n",
    "    ):\n",
    "\n",
    "    print(f\"{score} (moyen) : {mean:.04f} (+/-{std*2:.04f}) pour {params}\")\n",
    "\n",
    "###################################################################\n",
    "# Prédiction sur le jeu de test avec les hyperparamètres optimaux #\n",
    "###################################################################\n",
    "\n",
    "# GridSearchCV a automatiquement ré-entraîné le meilleur modèle sur l’intégralité du jeu d’entraînement.\n",
    "y_pred = grid.predict(X_test)\n",
    "print(f\"\\nScore sur le jeu de test (avec paramètres optimaux): {metrics.accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
